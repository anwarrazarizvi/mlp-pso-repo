{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Approximation\n",
    "### Using the PSO algorithm to optimise the ANN's parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Resources**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import resources\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#import ipywidgets as widgets\n",
    "#from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Create Neural Network Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:    \n",
    "    def __init__(self, func, hiddenLayerNeurons, activation, inputList, outputList):\n",
    "        self.func = func # name of the function to be optimized\n",
    "        self.layerArch = list.copy(hiddenLayerNeurons) #list of neurons in the hidden layers\n",
    "        self.activation = activation # name of the activation fuction\n",
    "          \n",
    "        self.inputArray = inputList # array of given input dataset\n",
    "        self.outputArray = outputList # array of the desired output dataset\n",
    "        #print(self.inputArray,self.outputArray)\n",
    "        \n",
    "        # adding input and output layers to the hidden neurons list\n",
    "        self.inputOutputNeurons()\n",
    "        \n",
    "        # calculate number of weights\n",
    "        self.nWeights = self.numWeights()\n",
    "        \n",
    "        # set activation function\n",
    "        self.actFunc = self.functionSelection()\n",
    "        \n",
    "        # set indices at which weight matrix to be split for matrix multiplication\n",
    "        self.splitIndices = self.splitIndices()\n",
    "        \n",
    "    def getANN_Hyperparameters(self):\n",
    "        return [self.func, self.actFunc, self.layerArch]\n",
    "        \n",
    "    def getnWeights(self): # getter methonds for number of weights\n",
    "        return self.nWeights\n",
    "        \n",
    "    def inputOutputNeurons(self): # a private method to neuralNetwork class\n",
    "        # Set number neurons in the Input layer\n",
    "        if self.func in ('XOR','Complex'):\n",
    "            self.layerArch.insert(0,2) # XOR & Complex functions are based on two input variables\n",
    "        else:\n",
    "            self.layerArch.insert(0,1) # Linear, Cubic, Sine, Tanh functions are based on single input variable\n",
    "       \n",
    "        # Set number of neurons in the Output layer\n",
    "        self.layerArch.append(1) # only single output value is expected from the fuction\n",
    "        \n",
    "    def numWeights(self):# a private method to neuralNetwork class\n",
    "        n_weights = sum(self.layerArch[i]*self.layerArch[i+1] for i in range(len(self.layerArch)-1))\n",
    "        return n_weights\n",
    "    \n",
    "    def functionSelection(self):# a private method to neuralNetwork class\n",
    "        return activation_funcs[self.activation]\n",
    "    \n",
    "    def splitIndices(self):\n",
    "        indices = []\n",
    "        for i in range(len(self.layerArch)-1):\n",
    "            indices.append(self.layerArch[i]*self.layerArch[i+1])\n",
    "\n",
    "        splitIndices = []\n",
    "        splitIndices.append(indices[0])\n",
    "        for j in range(1,len(indices)-1):\n",
    "            splitIndices.append(splitIndices[j-1] + indices[j])\n",
    "\n",
    "        return splitIndices\n",
    "    \n",
    "    def forward(self, weights):\n",
    "        \n",
    "        # to do: check the length of list of weigths matches the number weights\n",
    "        \n",
    "        wArray = np.split(weights,self.splitIndices)\n",
    "        #print(\"splitIndices\",self.splitIndices)\n",
    "        #print(\"wArray\",wArray)\n",
    "        #print(\"layerArch\", self.layerArch)\n",
    "        \n",
    "        wMatrix=[]\n",
    "        for i in range(0,len(self.layerArch)-1):\n",
    "            wMatrix.append(wArray[i].reshape(self.layerArch[i+1],self.layerArch[i]))\n",
    "        #print(\"wArray after reshape\", wMatrix)\n",
    "    \n",
    "        desiredArray = np.copy(self.outputArray)\n",
    "        predictArray = []\n",
    "        \n",
    "        for i in range(len(self.inputArray)):\n",
    "            ih = self.inputArray[i].reshape(-1,1)\n",
    "            for j in range(0,len(self.layerArch)-1):\n",
    "                #print(\"wMatrix = \", wMatrix[j], \"ih = \", ih)\n",
    "                ih = np.matmul(wMatrix[j],ih)\n",
    "            \n",
    "                if j != (len(self.layerArch)-1):\n",
    "                    ih = self.actFunc(ih)\n",
    "            predictArray.append(ih)\n",
    "            \n",
    "        #print(len(desiredArray), len(predictArray))\n",
    "\n",
    "        squeezePredict = np.squeeze(predictArray)\n",
    "\n",
    "        mse = ((desiredArray - squeezePredict)**2).mean(axis = None)\n",
    "       \n",
    "        return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Create PSO Class**<br>\n",
    "swarmsize - desired swarm size i.e. weight array<br>\n",
    "$ \\alpha \\gets$ inertia weight i.e. proportion of velocity to be retained<br>\n",
    "$ \\beta \\gets$ cognitive weight i.e. proportion of personal best to be retained<br>\n",
    "$ \\delta \\gets$ social weight i.e. proportion of global best to be retained<br>\n",
    "$ \\epsilon \\gets$ jump size of a particle<br><br>\n",
    "**Enforcing Boundaries**: enforced boundaries by Reinitialising the position of out of bounds particles<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-946cbb445c4e>, line 57)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-946cbb445c4e>\"\u001b[1;36m, line \u001b[1;32m57\u001b[0m\n\u001b[1;33m    self.data.append([epoch+1,i+1,,err_i,,best_part_error_i,best_swarm_err])\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class ParticleSwarmOptimizer:    \n",
    "    def __init__(self, swarm_size,pso_alpha, pso_beta, pso_delta, max_epochs, bound_max, bound_min):\n",
    "        # PSO parameters\n",
    "        self.swarmSize = swarm_size # number of particles in swarm\n",
    "        self.psoAlpha = pso_alpha # inertia weight\n",
    "        self.psoBeta = pso_beta # cognitive weight \n",
    "        self.psoDelta = pso_delta # social weight\n",
    "        self.maxEpochs = max_epochs # maximum number of iterations\n",
    "\n",
    "        self.bound_max = bound_max\n",
    "        self.bound_min = bound_min\n",
    "        \n",
    "        self.data =[] # list to record data\n",
    "\n",
    "    def getSwarmSize(self):\n",
    "        return self.swarmSize # no of particles in swarm\n",
    "    \n",
    "    def getRunData(self):\n",
    "        return self.data\n",
    "    \n",
    "    def getPSO_Hyperparameter(self):\n",
    "        return [self.swarmSize, self.psoAlpha, self.psoBeta, self.psoDelta, self.maxEpochs, self.bound_max, self.bound_min]\n",
    "   \n",
    "    def forward(self,swarm):\n",
    "        \n",
    "        # initialise global best position and fittness/error\n",
    "        best_swarm_pos = np.ones((swarm[0].getDim()))\n",
    "        best_swarm_err = 500\n",
    "        \n",
    "        data=[]\n",
    "        epoch = 0\n",
    "        while epoch < self.maxEpochs: # run until fixed number of iterations\n",
    "            \n",
    "            #Update global best\n",
    "            for ii in range(self.swarmSize): # for each particle in swarm/population\n",
    "                \n",
    "                position_ii = swarm[ii].getPosition()\n",
    "                err_ii = (swarm[ii].getError())\n",
    "  \n",
    "                # update Global/swarm best error and position if found comparing fitness/error\n",
    "                if err_ii < best_swarm_err:\n",
    "                    best_swarm_err = err_ii\n",
    "                    best_swarm_pos = position_ii\n",
    "                \n",
    "\n",
    "            for i in range(self.swarmSize): # for each particle in swarm/population\n",
    "                \n",
    "                # Gather information            \n",
    "                dim_i = swarm[i].getDim()\n",
    "                position_i = swarm[i].getPosition()\n",
    "                velocity_i = swarm[i].getVelocity()\n",
    "                best_part_error_i = swarm[i].getBestPartErr()\n",
    "                best_part_position_i = swarm[i].getBestPartPos()\n",
    "                err_i = swarm[i].getError()\n",
    "                \n",
    "                print('epoch:{:03d} ,particle:{:02d}, par err:{:0.5f}, best part err:{:0.5f}, best swarm err:{:0.2f}'.\n",
    "                      format(epoch+1, i+1, err_i, best_part_error_i ,best_swarm_err))\n",
    "                \n",
    "                #self.data.append([('epoch',epoch+1),('particle',i+1),('Particle Current Quality',err_i),('Particle Best Quality',best_part_error_i), ('Global Best Quality',best_swarm_err)])\n",
    "                self.data.append([epoch+1,i+1,err_i,,best_part_error_i,best_swarm_err])\n",
    "                  \n",
    "                \n",
    "                # compute particle new velocity\n",
    "                for k in range(dim_i): # for each dimension/weight in particle i\n",
    "                    a = self.psoAlpha*velocity_i[k]\n",
    "                    b = self.psoBeta*(best_part_position_i[k] - position_i[k])\n",
    "                    c = self.psoDelta*(best_swarm_pos[k] - position_i[k])\n",
    "                    velocity_i[k] = a+b+c\n",
    "\n",
    "                    \n",
    "                # compute particle new position\n",
    "                position_f = np.add(position_i,velocity_i)\n",
    "                \n",
    "                \n",
    "                # enforcing boundaries by Reinitialising the position of out of bounds particles\n",
    "                kk=0\n",
    "                while kk < dim_i:\n",
    "                    if position_f[kk] >= self.bound_max or position_f[kk] <= self.bound_min:\n",
    "                        position_f = (np.random.rand((dim_i)).astype(np.float32)-0.5)/2\n",
    "                        velocity_i = (np.random.rand((dim_i)).astype(np.float32)-0.5)/2\n",
    "                        print('weights breached at weights#',kk)\n",
    "                        break\n",
    "                    kk +=1\n",
    "                \n",
    "                              \n",
    "                # compute new fitness\n",
    "                new_err = swarm[i].ann.forward(position_f)\n",
    "                \n",
    "                # update particle best error and position if found comparing fitness/error\n",
    "                if new_err < best_part_error_i:\n",
    "                    swarm[i].setBestPartErr(new_err)\n",
    "                    swarm[i].setBestPartPos(position_f)\n",
    "                \n",
    "                # update particle class parameters              \n",
    "                swarm[i].setPosition(position_f) # update particle position\n",
    "                swarm[i].setVelocity(velocity_i) #update particle velocity\n",
    "                swarm[i].setError(new_err) #update particle current error\n",
    "                \n",
    "                #print('epoch:{:03d} ,particle:{:02d}, par err:{:0.5f}, best part err:{:0.5f}, best swarm err:{:0.2f}'.\n",
    "                      #format(epoch+1, i+1, new_err, swarm[i].getBestPartErr() ,best_swarm_err))\n",
    "            \n",
    "            \n",
    "            print('\\n--------------------------------------------------------------------------------------\\n')\n",
    "            epoch += 1\n",
    "        return best_swarm_pos \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Create Particles Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particles:\n",
    "    def __init__(self, ann):\n",
    "        self.ann = ann # neural network\n",
    "        self.dim = self.ann.getnWeights() # no. of weights in nurol network = dimension of particle\n",
    "        \n",
    "        # initialise particle best position and velocity with random values \n",
    "        self.position = (np.random.rand((self.dim)).astype(np.float64)-0.5)/2 #current position; initialized with random\n",
    "        self.velocity = (np.random.rand((self.dim)).astype(np.float64)-0.5)/2 #current velocity; initialized with random\n",
    "        \n",
    "        self.err = self.ann.forward(self.position)  #compute error for initial position\n",
    "        \n",
    "        self.best_part_pos = np.copy(self.position) # intialize particle best position as intial position\n",
    "        self.best_part_err = np.copy(self.err)  #intialized particle best error as self error from intial position\n",
    "        \n",
    "    # getter methods    \n",
    "    def getDim(self): return self.dim\n",
    "    def getPosition(self):return self.position\n",
    "    def getVelocity(self):return self.velocity\n",
    "    def getError(self):return self.err\n",
    "    def getBestPartErr(self):return self.best_part_err\n",
    "    def getBestPartPos(self):return self.best_part_pos\n",
    "\n",
    "    \n",
    "    # setter methods    \n",
    "    def setPosition(self,pos):self.position = np.copy(pos)\n",
    "    def setVelocity(self,vel):self.velocity = np.copy(vel)\n",
    "    def setError(self,err): self.err = np.copy(err)\n",
    "    def setBestPartErr(self,best_err): self.best_part_err = np.copy(best_err)\n",
    "    def setBestPartPos(self,best_pos): self.best_part_pos = np.copy(best_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "a = np.random.rand(3,3).astype(np.float32)-0.5\n",
    "print(a)\n",
    "\n",
    "a = np.random.rand(3,3).astype(np.float32)-0.5\n",
    "print(a)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select function from User input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Set function from User input\n",
    "func = input('Choose the function name \\n(Options: Linear, Cubic, Sine, TanH, XOR, Complex) = ')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Hyperparameters from User input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Set Hyperparameters from User input\n",
    "\n",
    "# set number of hidden layers\n",
    "hidden_layers = int(input('Enter number of hidden layers = '))\n",
    "\n",
    "\n",
    "# set number of neurons in the hidden layers\n",
    "if(hidden_layers > 0):\n",
    "    hidden_layer_neurons = []\n",
    "    for layer in range(hidden_layers):\n",
    "        hidden_layer_neurons.append(int(input('Enter number of nodes in hidden layer {}= '.format(layer+1))))\n",
    "  \n",
    "# set activation function\n",
    "activation = input('Enter the activation function \\n(Options: Null, Sigmoid, Hyperbolic Tangent, Cosine, Gaussian) = ')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting ANN Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = 'Cubic' #(Options: Linear, Cubic, Sine, TanH, XOR, Complex)\n",
    "hidden_layer_neurons = [5,5]\n",
    "activation = 'Sigmoid' # (Options: Null, Sigmoid, Hyperbolic Tangent, Cosine, Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to do: handling errors & exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#check only\n",
    "for i in range(len(hidden_layer_neurons)):\n",
    "    print(\"number of neurons in hidden layer {} is {}\".format(i+1,hidden_layer_neurons[i]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activation_funcs = {\n",
    "    'Null': lambda x: 0,\n",
    "    'Sigmoid': lambda x: 1/(1 + np.exp(-x)),\n",
    "    'Hyperbolic Tangent': lambda x: np.tanh(x),\n",
    "    'Cosine': lambda x: np.cos(x),\n",
    "    'Gaussian': lambda x: np.exp(-x**2/2),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#check only\n",
    "activate = activation_funcs[activation]\n",
    "print ('Output: Selected activation -',activate(.5))\n",
    "\n",
    "print('Output: Null -',0)\n",
    "print('Output: Sigmoid -',1/(1 + np.exp(-.5)))\n",
    "print('Output: Hyperbolic Tangent -',np.tanh(.5))\n",
    "print('Output: Cosine -',np.cos(.5))\n",
    "print('Output: Gaussian -',np.exp(-.5**2/2))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading data from the .txt file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the training data from .txt file into a list\n",
    "txt_address = {'Linear':'Data/1in_linear.txt',\n",
    "               'Cubic':'Data/1in_cubic.txt',\n",
    "               'Sine':'Data/1in_sine.txt',\n",
    "               'TanH':'Data/1in_tanh.txt',\n",
    "               'XOR':'Data/2in_xor.txt',\n",
    "               'Complex':'Data/2in_complex.txt'}\n",
    "\n",
    "train_data_file = open(txt_address[func],'r')\n",
    "line_data = train_data_file.readlines()\n",
    "train_data_file.close()\n",
    "\n",
    "train_list = []\n",
    "for line in line_data:\n",
    "    line = line.strip().split()\n",
    "    for d in line:\n",
    "        train_list.append(float(d))\n",
    "        \n",
    "#check     \n",
    "#print(train_list)\n",
    "\n",
    "if func in ('XOR','Complex'):\n",
    "    train_array = np.asarray(train_list, dtype=np.float32).reshape(-1,3)\n",
    "    X,Y = train_array[:,0:2], train_array[:,-1]\n",
    "\n",
    "elif func in ('Linear', 'Cubic', 'Sine', 'TanH'):\n",
    "    train_array = np.asarray(train_list, dtype=np.float32).reshape(-1,2)\n",
    "    X,Y = train_array[:,0], train_array[:,-1]\n",
    "else:\n",
    "    \"error reading data\"\n",
    "    \n",
    "#print(train_array)\n",
    "#print(X)\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create instance of neural network\n",
    "ann1 = NeuralNetwork(func, hidden_layer_neurons, activation, X,Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting PSO Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_size = 20\n",
    "pso_alpha = 0.7 #0.729\n",
    "pso_beta = 1.8 #1.49\n",
    "pso_delta = 1.8 #1.49\n",
    "\n",
    "max_epochs = 100\n",
    "bound =50\n",
    "\n",
    "bound_max = bound\n",
    "bound_min = -bound\n",
    "\n",
    "\n",
    "pso1 = ParticleSwarmOptimizer(swarm_size,pso_alpha,pso_beta,pso_delta,max_epochs, bound_max, bound_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create swarm with swarm_size particles\n",
    "swarm = [Particles(ann1) for i in range(pso1.getSwarmSize())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_weights = pso1.forward(swarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('final_weights01.csv',final_weights,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pso1.getRunData()[1])\n",
    "#data in format:\n",
    "#[('epoch',epoch+1),('particle',i+1),('Particle Current Quality',err_i),('Particle Best Quality',best_part_error_i), ('Global Best Quality',best_swarm_err)])\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
