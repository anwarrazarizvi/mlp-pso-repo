{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Approximation\n",
    "### Using the PSO algorithm to optimise the ANN's parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select function from User input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import resources\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Create Neural Network Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:    \n",
    "    def __init__(self, func, hiddenLayerNeurons, activation):\n",
    "        self.func = func # name of the function to be optimized\n",
    "        self.layerArch = list.copy(hiddenLayerNeurons) #list of neurons in the hidden layers\n",
    "        self.activation = activation # name of the activation fuction\n",
    "         \n",
    "        # adding input and output layers to the hidden neurons list\n",
    "        self.inputOutputNeurons()\n",
    "        \n",
    "        # calculate number of weights\n",
    "        self.nWeights = self.numWeights()\n",
    "        \n",
    "        # set activation function\n",
    "        self.actFunc = self.functionSelection()\n",
    "        \n",
    "        # set indices at which weight matrix to be split for matrix multiplication\n",
    "        self.splitIndices = self.splitIndices()\n",
    "        \n",
    "    def getANN_Hyperparameters(self):\n",
    "        return [self.func, self.activation, self.layerArch]\n",
    "        \n",
    "    def getnWeights(self): # getter methonds for number of weights\n",
    "        return self.nWeights\n",
    "        \n",
    "    def inputOutputNeurons(self): # a private method to neuralNetwork class\n",
    "        # Set number neurons in the Input layer\n",
    "        if self.func in ('XOR','Complex'):\n",
    "            self.layerArch.insert(0,2) # XOR & Complex functions are based on two input variables\n",
    "        else:\n",
    "            self.layerArch.insert(0,1) # Linear, Cubic, Sine, Tanh functions are based on single input variable\n",
    "       \n",
    "        # Set number of neurons in the Output layer\n",
    "        self.layerArch.append(1) # only single output value is expected from the fuction\n",
    "        \n",
    "    def numWeights(self):# a private method to neuralNetwork class\n",
    "        n_weights = sum(self.layerArch[i]*self.layerArch[i+1] for i in range(len(self.layerArch)-1))\n",
    "        return n_weights\n",
    "    \n",
    "    def functionSelection(self):# a private method to neuralNetwork class\n",
    "        return activation_funcs[self.activation]\n",
    "    \n",
    "    def splitIndices(self):\n",
    "        indices = []\n",
    "        for i in range(len(self.layerArch)-1):\n",
    "            indices.append(self.layerArch[i]*self.layerArch[i+1])\n",
    "\n",
    "        splitIndices = []\n",
    "        splitIndices.append(indices[0])\n",
    "        for j in range(1,len(indices)-1):\n",
    "            splitIndices.append(splitIndices[j-1] + indices[j])\n",
    "\n",
    "        return splitIndices\n",
    "    \n",
    "    def forward(self, weights,X,Y):\n",
    "        \n",
    "        inputArray = np.copy(X)\n",
    "       \n",
    "        wArray = np.split(weights,self.splitIndices)\n",
    "        #print(\"splitIndices\",self.splitIndices)\n",
    "        #print(\"wArray\",wArray)\n",
    "        #print(\"layerArch\", self.layerArch)\n",
    "        \n",
    "        wMatrix=[]\n",
    "        for i in range(0,len(self.layerArch)-1):\n",
    "            wMatrix.append(wArray[i].reshape(self.layerArch[i+1],self.layerArch[i]))\n",
    "        #print(\"wArray after reshape\", wMatrix)\n",
    "    \n",
    "        desiredArray = np.copy(Y)\n",
    "        predictArray = []\n",
    "        \n",
    "        for i in range(len(inputArray)):\n",
    "            ih = inputArray[i].reshape(-1,1)\n",
    "            for j in range(0,len(self.layerArch)-1):\n",
    "                #print(\"wMatrix = \", wMatrix[j], \"ih = \", ih)\n",
    "                ih = np.matmul(wMatrix[j],ih)\n",
    "            \n",
    "                if j != (len(self.layerArch)-1):\n",
    "                    ih = self.actFunc(ih)\n",
    "            predictArray.append(ih)\n",
    "            \n",
    "        #print(len(desiredArray), len(predictArray))\n",
    "\n",
    "        squeezePredict = np.squeeze(predictArray)\n",
    "\n",
    "        mse = ((desiredArray - squeezePredict)**2).mean(axis = None)\n",
    "       \n",
    "        return mse.tolist(), squeezePredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Helper function for passing activation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activation_funcs = {\n",
    "    'Null': lambda x: x*0,\n",
    "    'Sigmoid': lambda x: 1/(1 + np.exp(-x)),\n",
    "    'Hyperbolic Tangent': lambda x: np.tanh(x),\n",
    "    'Cosine': lambda x: np.cos(x),\n",
    "    'Gaussian': lambda x: np.exp(-x**2/2),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Function to read data from the .txt file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training data from .txt file into a list\n",
    "def read_data(func):\n",
    "    txt_address = {'Linear':'Data/1in_linear.txt',\n",
    "                   'Cubic':'Data/1in_cubic.txt',\n",
    "                   'Sine':'Data/1in_sine.txt',\n",
    "                   'TanH':'Data/1in_tanh.txt',\n",
    "                   'XOR':'Data/2in_xor.txt',\n",
    "                   'Complex':'Data/2in_complex.txt'}\n",
    "\n",
    "    train_data_file = open(txt_address[func],'r')\n",
    "    line_data = train_data_file.readlines()\n",
    "    train_data_file.close()\n",
    "\n",
    "    train_list = []\n",
    "    for line in line_data:\n",
    "        line = line.strip().split()\n",
    "        for d in line:\n",
    "            train_list.append(float(d))\n",
    "        \n",
    "    #check     \n",
    "    #print(train_list)\n",
    "\n",
    "    if func in ('XOR','Complex'):\n",
    "        train_array = np.asarray(train_list, dtype=np.float32).reshape(-1,3)\n",
    "        X,Y = train_array[:,0:2], train_array[:,-1]\n",
    "\n",
    "    elif func in ('Linear', 'Cubic', 'Sine', 'TanH'):\n",
    "        train_array = np.asarray(train_list, dtype=np.float32).reshape(-1,2)\n",
    "        X,Y = train_array[:,0], train_array[:,-1]\n",
    "    else:\n",
    "        \"error reading data\"    \n",
    "    #print(train_array)\n",
    "    #print(X)\n",
    "    #print(Y)\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#func = (Options: Linear, Cubic, Sine, TanH, XOR, Complex)\n",
    "#hidden_layer_neurons = [7,7]\n",
    "# activation = (Options: Null, Sigmoid, Hyperbolic Tangent, Cosine, Gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select function from User input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose the function name \n",
      "(Options: Linear, Cubic, Sine, TanH, XOR, Complex) = XOR\n"
     ]
    }
   ],
   "source": [
    "# Set function from User input\n",
    "func = input('Choose the function name \\n(Options: Linear, Cubic, Sine, TanH, XOR, Complex) = ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if func == 'Linear':\n",
    "    hidden_layer_neurons = [7,7]\n",
    "    activation = 'Hyperbolic Tangent' \n",
    "    weights = np.genfromtxt('linear_weights.csv',delimiter = ',')\n",
    "elif func == 'Cubic':\n",
    "    hidden_layer_neurons = [7,7]\n",
    "    activation = 'Sigmoid' \n",
    "    weights = np.genfromtxt('cubic_weights.csv',delimiter = ',')\n",
    "elif func == 'Sine':\n",
    "    hidden_layer_neurons = [7,7]\n",
    "    activation = 'Sigmoid' \n",
    "    weights = np.genfromtxt('sine_weights.csv',delimiter = ',')\n",
    "elif func == 'TanH':\n",
    "    hidden_layer_neurons = [7,7]\n",
    "    activation = 'Sigmoid' \n",
    "    weights = np.genfromtxt('tanh_weights.csv',delimiter = ',') \n",
    "elif func == 'XOR':\n",
    "    hidden_layer_neurons = [7,7]\n",
    "    activation = 'Sigmoid' \n",
    "    weights = np.genfromtxt('xor_weights.csv',delimiter = ',') \n",
    "elif func == 'Complex':\n",
    "    hidden_layer_neurons = [7,7]\n",
    "    activation = 'Sigmoid' \n",
    "    weights = np.genfromtxt('complex_weights.csv',delimiter = ',') \n",
    "else: 'function not found'\n",
    "    \n",
    "X,Y = read_data(func) # read data\n",
    "ann_object = NeuralNetwork(func, hidden_layer_neurons, activation) #create instance of neural network\n",
    "mse, predict_array = ann_object.forward(weights,X,Y) #run ann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.831762878573905e-25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47,\n",
       "       2.84438677e-24, 1.00000000e+00, 1.00000000e+00, 9.09263243e-47])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.000e+00, -9.412e-01, -8.847e-01, -8.306e-01, -7.787e-01,\n",
       "       -7.290e-01, -6.815e-01, -6.361e-01, -5.927e-01, -5.514e-01,\n",
       "       -5.120e-01, -4.746e-01, -4.390e-01, -4.052e-01, -3.732e-01,\n",
       "       -3.430e-01, -3.144e-01, -2.875e-01, -2.621e-01, -2.383e-01,\n",
       "       -2.160e-01, -1.951e-01, -1.756e-01, -1.575e-01, -1.406e-01,\n",
       "       -1.250e-01, -1.106e-01, -9.730e-02, -8.520e-02, -7.410e-02,\n",
       "       -6.400e-02, -5.490e-02, -4.670e-02, -3.930e-02, -3.280e-02,\n",
       "       -2.700e-02, -2.200e-02, -1.760e-02, -1.380e-02, -1.060e-02,\n",
       "       -8.000e-03, -5.800e-03, -4.100e-03, -2.700e-03, -1.700e-03,\n",
       "       -1.000e-03, -5.000e-04, -2.000e-04, -1.000e-04, -0.000e+00,\n",
       "        0.000e+00,  0.000e+00,  1.000e-04,  2.000e-04,  5.000e-04,\n",
       "        1.000e-03,  1.700e-03,  2.700e-03,  4.100e-03,  5.800e-03,\n",
       "        8.000e-03,  1.060e-02,  1.380e-02,  1.760e-02,  2.200e-02,\n",
       "        2.700e-02,  3.280e-02,  3.930e-02,  4.670e-02,  5.490e-02,\n",
       "        6.400e-02,  7.410e-02,  8.520e-02,  9.730e-02,  1.106e-01,\n",
       "        1.250e-01,  1.406e-01,  1.575e-01,  1.756e-01,  1.951e-01,\n",
       "        2.160e-01,  2.383e-01,  2.621e-01,  2.875e-01,  3.144e-01,\n",
       "        3.430e-01,  3.732e-01,  4.052e-01,  4.390e-01,  4.746e-01,\n",
       "        5.120e-01,  5.514e-01,  5.927e-01,  6.361e-01,  6.815e-01,\n",
       "        7.290e-01,  7.787e-01,  8.306e-01,  8.847e-01,  9.412e-01,\n",
       "        1.000e+00], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.3236537 ,  7.18997526,  7.74595356, -2.15785027, -3.23931241,\n",
       "        7.3099966 ,  4.44442892,  3.45061707,  5.44892263, -2.2571466 ,\n",
       "        4.71485519,  6.47529888, -5.363626  , -0.07585157, -4.96638012,\n",
       "       -5.76920986,  6.3554163 , -2.19711161, -0.83127081, -7.14089584,\n",
       "        1.84995413, -0.06581387, -0.89636129,  2.58535647,  1.68581426,\n",
       "       -4.10262871, -5.92509127, -0.9401741 , -5.09147263,  2.98236489,\n",
       "       -4.45628738,  4.02693129, -4.12015247,  4.77184677, -2.82231283,\n",
       "        3.00362015, -1.25777185, -0.49890324,  2.47032142, -3.78417635,\n",
       "        6.15933323,  2.79662132, -6.24527264, -2.20835686, -5.77047157,\n",
       "        5.87540054,  8.05151463, -1.94345593,  2.10212421,  0.86339676,\n",
       "        3.40300202, -3.48573875,  2.6052587 , -4.54325771,  1.18287933,\n",
       "        8.69890022, -9.59002781, -2.71130681, -5.37482643, -7.46158123,\n",
       "       -0.31633696, -6.59423351,  8.09544182])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
